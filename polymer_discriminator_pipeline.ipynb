{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AP2p4zxmhaLf",
        "outputId": "06a6f4cf-395d-491c-ab14-23ab14b08ecc"
      },
      "outputs": [],
      "source": [
        "# %%capture --no-stderr\n",
        "# ! pip install rdkit deepchem torch_geometric dgllife\n",
        "# ! pip install -f https://download.pytorch.org/whl/cu118/torch_stable.html torch==2.2.1+cu118\n",
        "# ! pip install  dgl -f https://data.dgl.ai/wheels/torch-2.2/cu121/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No normalization for SPS. Feature removed!\n",
            "No normalization for AvgIpc. Feature removed!\n",
            "2024-09-13 13:59:02.718331: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-13 13:59:02.803911: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-13 13:59:02.825236: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-13 13:59:02.965247: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-13 13:59:04.375393: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/kalki/imported/career/open_source/venv/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
            "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (/home/kalki/imported/career/open_source/venv/lib/python3.10/site-packages/deepchem/models/torch_models/__init__.py)\n",
            "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
          ]
        }
      ],
      "source": [
        "import deepchem as dc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "36xHJU2gkvcF"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "from deepchem.feat.molecule_featurizers import MATFeaturizer, MolGraphConvFeaturizer, DMPNNFeaturizer\n",
        "from deepchem.models.torch_models import GCNModel, MATModel, DMPNNModel\n",
        "from deepchem.data import NumpyDataset, CSVLoader\n",
        "import numpy as numpy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from deepchem.metrics import mean_squared_error, Metric, accuracy_score\n",
        "import pandas as pd\n",
        "from deepchem.models.losses import SparseSoftmaxCrossEntropy\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oVmsSz6ikWsA"
      },
      "outputs": [],
      "source": [
        "featurizer_mapper = {\n",
        "    \"GCN\": MolGraphConvFeaturizer,\n",
        "    \"MAT\": MATFeaturizer,\n",
        "    \"DMPNN\": DMPNNFeaturizer\n",
        "}\n",
        "\n",
        "model_mapper = {\n",
        "    \"GCN\": GCNModel,\n",
        "    \"MAT\": MATModel,\n",
        "    \"DMPNN\": DMPNNModel\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "def crossEntropyLoss(output, labels):\n",
        "    ce_loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "    # Convert (batch_size, tasks, classes) to (batch_size, classes, tasks)\n",
        "    # CrossEntropyLoss only supports (batch_size, classes, tasks)\n",
        "    if len(output.shape) == 3:\n",
        "        output = output.permute(0, 2, 1)\n",
        "\n",
        "    if len(labels.shape) == len(output.shape):\n",
        "        labels = labels.squeeze(-1)\n",
        "    return ce_loss(torch.tensor(output), torch.tensor(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PolymerDiscriminatorPipeline():\n",
        "  def __init__(self, task: str, model_name: str, batch_size: int = 3):\n",
        "    ALLOWED_MODELS = [\"GCN\", \"MAT\", \"DMPNN\"]\n",
        "\n",
        "    if task not in [\"regression\", \"classification\"]:\n",
        "      raise ValueError(\"Task must be either 'regression' or 'classification'\")\n",
        "\n",
        "    if model_name not in ALLOWED_MODELS:\n",
        "      raise ValueError(f\"Model must be one of {ALLOWED_MODELS}\")\n",
        "\n",
        "    self.task = task\n",
        "    self.model_name = model_name\n",
        "    self.batch_size = batch_size\n",
        "    self.model = None\n",
        "\n",
        "\n",
        "  def _prepare_data(self, df, train_ratio: float = 0.8):\n",
        "    train_df, test_df = train_test_split(df, test_size=1-train_ratio, random_state=42)\n",
        "    train_df.to_csv(\"train.csv\")\n",
        "    test_df.to_csv(\"test.csv\")\n",
        "    return \"train.csv\", \"test.csv\"\n",
        "\n",
        "  def _featurize(self, train_path, test_path):\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    test_df = pd.read_csv(test_path)\n",
        "\n",
        "    featurizer = featurizer_mapper[self.model_name]()\n",
        "\n",
        "    X_train = featurizer.featurize(train_df[\"smiles\"].values)\n",
        "    y_train = train_df[\"value\"].values\n",
        "\n",
        "    X_test = featurizer.featurize(test_df[\"smiles\"].values)\n",
        "    y_test = test_df[\"value\"].values\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "  def _prepare_input(self, X_train, y_train, X_test, y_test):\n",
        "    train_dataset = NumpyDataset(X_train, y_train)\n",
        "    test_dataset = NumpyDataset(X_test, y_test)\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "  def _train(self, train_dataset, num_epochs):\n",
        "    if self.task == \"regression\":\n",
        "      model = model_mapper[self.model_name](mode=self.task, batch_size=self.batch_size, n_tasks = 1)\n",
        "    else:\n",
        "      max_target_encode = train_dataset.y.max()\n",
        "      model = model_mapper[self.model_name](mode=self.task, batch_size=self.batch_size, n_tasks = 1, n_classes = max_target_encode + 1)\n",
        "    train_loss = model.fit(train_dataset, nb_epoch=num_epochs)\n",
        "    return model, train_loss\n",
        "\n",
        "  def _evaluate(self, model, test_dataset):\n",
        "    if self.task == \"regression\":\n",
        "      metric = Metric(mean_squared_error)\n",
        "      test_loss = model.evaluate(test_dataset, [metric])\n",
        "    else:\n",
        "      pred = model.predict(test_dataset)\n",
        "      test_loss = crossEntropyLoss(pred, test_dataset.y)\n",
        "      test_loss = test_loss.mean().item()\n",
        "    return test_loss\n",
        "\n",
        "  def __call__(self, df, num_epochs, train_ratio: float = 0.8):\n",
        "    train_path, test_path = self._prepare_data(df, train_ratio)\n",
        "    if self.model_name == \"MAT\":\n",
        "      data_loader = CSVLoader(tasks=['value'], feature_field='smiles', featurizer=featurizer_mapper[self.model_name]())\n",
        "      train_dataset = data_loader.create_dataset(train_path)\n",
        "      test_dataset = data_loader.create_dataset(test_path)\n",
        "    else:\n",
        "      X_train, y_train, X_test, y_test = self._featurize(train_path, test_path)\n",
        "      train_dataset, test_dataset = self._prepare_input(X_train, y_train, X_test, y_test)\n",
        "    model, train_loss = self._train(train_dataset, num_epochs)\n",
        "    test_loss = self._evaluate(model, test_dataset)\n",
        "    report = {\n",
        "        \"model\" : self.model_name,\n",
        "        \"task\" : self.task,\n",
        "        \"train_loss\" : train_loss,\n",
        "        \"test_loss\" : test_loss\n",
        "    }\n",
        "    self.model = model\n",
        "    return report\n",
        "\n",
        "  def _predict(self):\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regression Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Pkb9b4QSvhFB",
        "outputId": "2f9e43fe-604e-4d6f-97cf-6f743d8cee96"
      },
      "outputs": [],
      "source": [
        "! wget \"https://media.githubusercontent.com/media/ChangwenXu98/TransPolymer/master/data/Xc.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "jL5xfEAwvksp",
        "outputId": "82108970-5ddc-4846-8aaf-1d806093e46e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of data points 432\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smiles</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>*C*</td>\n",
              "      <td>47.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>*CC(*)C</td>\n",
              "      <td>44.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>*CC(*)CC</td>\n",
              "      <td>34.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>*CC(*)CCC</td>\n",
              "      <td>20.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>*CC(*)CC(C)C</td>\n",
              "      <td>21.64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         smiles  value\n",
              "0           *C*  47.80\n",
              "1       *CC(*)C  44.47\n",
              "2      *CC(*)CC  34.04\n",
              "3     *CC(*)CCC  20.01\n",
              "4  *CC(*)CC(C)C  21.64"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg_df = pd.read_csv(\"Xc.csv\")\n",
        "print(\"Number of data points\", reg_df.shape[0])\n",
        "reg_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kalki/imported/career/open_source/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GCN regression report >> {'model': 'GCN', 'task': 'regression', 'train_loss': 332.1333984375, 'test_loss': {'mean_squared_error': 436.2612318083791}}\n"
          ]
        }
      ],
      "source": [
        "gcn_reg_pipeline = PolymerDiscriminatorPipeline(task=\"regression\", model_name=\"GCN\")\n",
        "gcn_reg_report = gcn_reg_pipeline(reg_df, num_epochs = 10)\n",
        "print(\"GCN regression report >>\", gcn_reg_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "mat_reg_pipeline = PolymerDiscriminatorPipeline(task=\"regression\", model_name=\"MAT\")\n",
        "mat_reg_report = mat_reg_pipeline(reg_df, num_epochs = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAT regression report >> {'model': 'MAT', 'task': 'regression', 'train_loss': 429.86886160714283, 'test_loss': {'mean_squared_error': 608.1135541170149}}\n"
          ]
        }
      ],
      "source": [
        "print(\"MAT regression report >>\", mat_reg_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qYn9sEolvBpY",
        "outputId": "ac45be37-4fe5-40ce-9801-48aca0529bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DMPNN regression report >> {'model': 'DMPNN', 'task': 'regression', 'train_loss': 489.2893359375, 'test_loss': {'mean_squared_error': 539.4306195095185}}\n"
          ]
        }
      ],
      "source": [
        "dmpnn_reg_pipeline = PolymerDiscriminatorPipeline(task=\"regression\", model_name=\"DMPNN\")\n",
        "dmpnn_reg_report = dmpnn_reg_pipeline(reg_df, num_epochs = 10)\n",
        "print(\"DMPNN regression report >>\", dmpnn_reg_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_df = pd.read_csv(\"OPV_cat_split.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "gcn_class_pipeline = PolymerDiscriminatorPipeline(task=\"classification\", model_name=\"GCN\")\n",
        "gcn_class_report = gcn_class_pipeline(class_df, num_epochs = 2)\n",
        "print(\"GCN classification report >>\", gcn_class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dmpnn_class_pipeline = PolymerDiscriminatorPipeline(task=\"classification\", model_name=\"DMPNN\")\n",
        "dmpnn_class_report = dmpnn_class_pipeline(class_df, num_epochs = 2)\n",
        "print(\"DMPNN classification report >>\", dmpnn_class_pipeline )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
